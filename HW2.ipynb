{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3545b554-4066-4ecf-ba62-f1f7bf5f66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, precision_recall_curve\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04e6d9d-2a1e-4e3a-bdb3-24d9a82ba1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('articles.csv')\n",
    "users = pd.read_csv('users_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3be4d1-fe34-4bf0-bc8d-49f6d016d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "    \n",
    "stopword_ru += additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3310695a-ebb0-4119-b6bf-7780641b7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a34a09e-da9d-4f97-ad66-1929a29e8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)\n",
    "texts = [t for t in news['title'].values]\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]\n",
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary)\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "lda = LdaModel.load(temp_file)\n",
    "other_texts = [t for t in news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "unseen_doc = other_corpus[2]\n",
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "576208e5-d307-4e47-890c-71e7e167e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_aggf(aggf):\n",
    "    def get_lda_vector(text):\n",
    "        unseen_doc = common_dictionary.doc2bow(text)\n",
    "        lda_tuple = lda[unseen_doc]\n",
    "        not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "        num_topics = 25\n",
    "\n",
    "        output_vector = []\n",
    "\n",
    "        for i in range(num_topics):\n",
    "            if i not in not_null_topics:\n",
    "                output_vector.append(0)\n",
    "            else:\n",
    "                output_vector.append(not_null_topics[i])\n",
    "        return np.array(output_vector)\n",
    "    \n",
    "    num_topics = 25\n",
    "    topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "    topic_matrix.columns = ['topic_{}'.format(i) for i in range(num_topics)]\n",
    "    topic_matrix['doc_id'] = news['doc_id'].values\n",
    "    topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(num_topics)]]\n",
    "    doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(num_topics)]].values))\n",
    "    \n",
    "    def get_user_embedding(user_articles_list):\n",
    "        user_articles_list = eval(user_articles_list)\n",
    "        user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "        user_vector = aggf(user_vector, 0)\n",
    "        return user_vector\n",
    "\n",
    "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "    user_embeddings.columns = ['topic_{}'.format(i) for i in range(num_topics)]\n",
    "    user_embeddings['uid'] = users['uid'].values\n",
    "    user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(num_topics)]]\n",
    "    \n",
    "    target = pd.read_csv('users_churn.csv')\n",
    "    X = pd.merge(user_embeddings, target, 'left')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(num_topics)]], \n",
    "                                                        X['churn'], random_state=0)\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    preds = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    "    return thresholds[ix], fscore[ix], precision[ix], recall[ix], roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3052c858-abe0-480b-b86e-6032d5072501",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['F-Score', 'Precision', 'Recall', 'Roc_Auc_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbbc59ea-87bf-4dc1-9f84-14ece84b6a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold = 0.27367\n",
      "F-Score = 0.66171\n",
      "Precision = 0.60751\n",
      "Recall = 0.72653\n",
      "Roc_Auc_Score = 0.93921\n"
     ]
    }
   ],
   "source": [
    "metrics_results_mean = []\n",
    "\n",
    "for i in do_aggf(np.mean)[1:]:\n",
    "    metrics_results_mean.append(i)\n",
    "\n",
    "print(f'Best Threshold = {round(do_aggf(np.mean)[0], 5)}')\n",
    "\n",
    "for result, name in zip(metrics_results_mean, metrics_names):\n",
    "    print(f'{name} = {round(result, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c8ecd-ebaf-4bc5-b93e-2856ac26cb5b",
   "metadata": {},
   "source": [
    "#### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66738d78-12b3-4409-9e33-bb2e6ada8f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold = 0.27606\n",
      "F-Score = 0.70928\n",
      "Precision = 0.71667\n",
      "Recall = 0.70204\n",
      "Roc_Auc_Score = 0.95459\n"
     ]
    }
   ],
   "source": [
    "# Используем медиану\n",
    "\n",
    "metrics_results_median = []\n",
    "\n",
    "for i in do_aggf(np.median)[1:]:\n",
    "    metrics_results_median.append(i)\n",
    "\n",
    "print(f'Best Threshold = {round(do_aggf(np.median)[0], 5)}')\n",
    "\n",
    "for result, name in zip(metrics_results_median, metrics_names):\n",
    "    print(f'{name} = {round(result, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5ae48-2e5c-4972-9692-ad23272169f3",
   "metadata": {},
   "source": [
    "#### Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ef23dc-7ea4-4f7a-8d70-e1782197b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold = 0.33607\n",
      "F-Score = 0.778\n",
      "Precision = 0.75\n",
      "Recall = 0.80816\n",
      "Roc_Auc_Score = 0.96883\n"
     ]
    }
   ],
   "source": [
    "# Используем максимум\n",
    "\n",
    "metrics_results_max = []\n",
    "\n",
    "for i in do_aggf(np.max)[1:]:\n",
    "    metrics_results_max.append(i)\n",
    "\n",
    "print(f'Best Threshold = {round(do_aggf(np.max)[0], 5)}')\n",
    "\n",
    "for result, name in zip(metrics_results_max, metrics_names):\n",
    "    print(f'{name} = {round(result, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc38e3-dda1-4217-8a40-2e31a00a919a",
   "metadata": {},
   "source": [
    "#### Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f331b0a1-d8e1-44c5-8b84-2c5d4ab45c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F-Score</td>\n",
       "      <td>0.661710</td>\n",
       "      <td>0.709278</td>\n",
       "      <td>0.777996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.607509</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.702041</td>\n",
       "      <td>0.808163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roc_Auc_Score</td>\n",
       "      <td>0.939208</td>\n",
       "      <td>0.954593</td>\n",
       "      <td>0.968831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Metrics      Mean    Median       Max\n",
       "0        F-Score  0.661710  0.709278  0.777996\n",
       "1      Precision  0.607509  0.716667  0.750000\n",
       "2         Recall  0.726531  0.702041  0.808163\n",
       "3  Roc_Auc_Score  0.939208  0.954593  0.968831"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame(data = {'Metrics': metrics_names,\n",
    "                               'Mean': metrics_results_mean,\n",
    "                               'Median': metrics_results_median,\n",
    "                               'Max': metrics_results_max})\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15566f75-299a-4ffd-9ee4-6b70208ef296",
   "metadata": {},
   "source": [
    "#### Задание 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8f067-8fdb-481e-a9e6-73be0b093e4a",
   "metadata": {},
   "source": [
    "Используя максимум, мы получаем более высокие результаты. Расчёт среднего выглядит хуже всего.\n",
    "Используя медиану, мы получаем довольно сбалансированные и близкие друг к другу значения, у максимума разброс чуть больше.\n",
    "У максимума сильно выделяется Recall на фоне остальных. Если в задаче бизнеса стоит максимизировать Recall, то неплохо использовать максимум для расчёта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74afa6-b65c-4ee5-b357-2063685618be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
